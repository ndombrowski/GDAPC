# Data types and structures

## Collecting data

Data collection considerations:

- How the data will be collected
- Choose data sources
- Decide what data to use
- How much data to collect
- Select the right data type
- Determine the timeframe for data collection, If you need an immediate answer, you might not have time to collect new data. In this case, you would need to use historical data that already exists. 

Data sources:

- **First-party data**: data collected by yourself, an individual or group using their own resources; typically the preferred method because we know where the data came from. For example data from an interview you conducted 
- **Second-party data**: data collected by a group directly from its audience and then sold. I.e. demographic data collected by a university or census data gathered by the government
- **Third-party data**: data collected from outside sources who did not collect it directly and might come from a number of different sources

Data collection:

- A **population** refers to all possible data values in a certain data set, which can be pretty challenging
- A **sample** is a part of a population that is representative of this population


## Data formats and structures

### Basic terminology

- **Continuous data** is measured and can have almost any numeric value, i.e. the running time of a movie
- **Discrete data**: Data that's counted and has a limited number of values. For example number of people who visit a hospital on a daily basis (10, 20, 200) or the rooms max. allowed capacity or sold tickets per month

- **Nominal data**: A type of qualitative data that is organized without a set order; i.e. yes, no, or unsure
- **Ordinal data**: A type of qualitative data with a set order or scale; i.e. if we ask a group of people to rank a movie from 1-5


- **Internal data**: Data that lives within a companies own system, also called primary data. I.e. Wages of employees tracked by HR or product inventory levels
- **External data**: data that lives and is generated outside of an organization, also called secondary data. I.e. National average wages for the various positions throughout your organization


- **Structured data**: data that's organized in a certain format, such as rows and columns. Spreadsheets and relational databases are two examples of software that store data in a structured way. Structured data that is grouped together to form relations enables analysts to more easily store, search, and analyze the data.
- **Unstructured data**: data that is not organized in any easily identifiable manner, i.e. audio or video files


### Structured data

Structured data works well in a **data model**, i.e. a model that is used for organizing data elements and how they relate to each other. **Data elements** are pieces of information, such as people's names or account numbers or addresses. 


### Data modeling levels and techniques

**Data modeling** is the process of creating diagrams that visually represent how data is organized and structured.  These visual representations are called **data models**. 

Different levels of data modeling have a different level of detail:

- **Conceptual data modeling** gives a high-level view of the data structure, such as how data interacts across an organization. For example, a conceptual data model may be used to define the business requirements for a new database. A conceptual data model doesn't contain technical details. 
- **Logical data modeling** focuses on the technical details of a database such as relationships, attributes, and entities. For example, a logical data model defines how individual records are uniquely identified in a database. But it doesn't spell out actual names of database tables. That's the job of a physical data model.
- **Physical data modeling** depicts how a database operates. A physical data model defines all entities and attributes used; for example, it includes table names, column names, and data types for the database.

More information can be found in this [comparison of data models](https://www.1keydata.com/datawarehousing/data-modeling-levels.html)​.


There are a lot of approaches when it comes to developing data models, but two common methods are the **Entity Relationship Diagram (ERD)** and the **Unified Modeling Language (UML)** diagram. ERDs are a visual way to understand the relationship between entities in the data model. UML diagrams are very detailed diagrams that describe the structure of a system by showing the system's entities, attributes, operations, and their relationships. 

You can read more about ERD, UML, and data dictionaries in this [data modeling techniques article](https://dataedo.com/blog/basic-data-modeling-techniques). 


## Data types, field and values

- **Data type**: A specific kind of data attribute that tells what kind of value the data is. Data types can be different depending on the query language you're using


### Data types in spreadsheets

- Number
- Text or string: A sequence of characters and punctuation that contains textual information
- Boolean: A data type with only two possible values, such as True and False


### Boolean logic

Conditions are created with **Boolean operators**, including AND, OR, and NOT. These operators are similar to mathematical operators and can be used to create logical statements that filter your results. 

Imagine you are shopping for shoes, and are considering certain preferences:

- You will buy the shoes only if they are pink and grey using `IF (Color="Grey") AND (Color="""Pink") `
- You will buy the shoes if they are entirely pink or entirely grey, or if they are pink and grey using `IF (Color="Grey") OR (Color="Pink")`
- You will buy the shoes if they are grey, but not if they have any pink using `IF (Color="Grey") AND (Color=NOT “Pink")`

<img width=400 src="../images/boolean.png">

- Learn about who pioneered Boolean logic in this historical article: [Origins of Boolean Algebra in the Logic of Classes](https://www.maa.org/press/periodicals/convergence/origins-of-boolean-algebra-in-the-logic-of-classes-george-boole-john-venn-and-c-s-peirce).
- Find more information about using AND, OR, and NOT from these [tips for searching with Boolean operators](https://libguides.mit.edu/c.php?g=175963&p=1158594).


### Data table components

- Row - Record
- Column - Field


### Wide and long data

- **Wide data**:  every data subject has a single row with multiple columns to hold the values of various attributes of the subject. Wide data lets you easily identify and quickly compare different columns. Wide data is preferred when:
    - Creating tables and charts with a few variables about each subject
    - Comparing straightforward line graphs

- **Long data**: data in which each row is one time point per subject, so each subject will have data in multiple rows. Long data is a great format for storing and organizing data when there's multiple variables for each subject at each time point that we want to observe. With this long data format, we can store and analyze all of this data using fewer columns. This is the preferred format when:
    - Storing a lot of variables about each subject. For example, 60 years worth of interest rates for each bank
    - Performing advanced statistical analysis or graphing 


### Data transformation

= the process of changing the data’s format, structure, or values.

Data transformation usually involves:

- Adding, copying, or replicating data 
- Deleting fields or records 
- Standardizing the names of variables
- Renaming, moving, or combining columns in a database
- Joining one set of data with another
- Saving a file in a different format. For example, saving a spreadsheet as a comma separated values (CSV) file.

Goals for data transformation might be: 

- Data organization: better organized data is easier to use
- Data compatibility: different applications or systems can then use the same data
- Data migration: data with matching formats can be moved from one system to another
- Data merging: data with the same organization can be merged together
- Data enhancement: data can be displayed with more detailed fields 
- Data comparison: apples-to-apples comparisons of the data can then be made 



