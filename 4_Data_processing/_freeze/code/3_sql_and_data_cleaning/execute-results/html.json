{
  "hash": "5a19981d7fd48f6336897c021316411a",
  "result": {
    "markdown": "---\ntitle: \"Using SQL to clean data\"\nexecute: \n  eval: false\n---\n\nSpreadsheets:\n- Generated with a program\n- Access to the data you input\n- Stored locally\n- Smaller datasets\n- Work on it independently\n- Build-in functionalities\n\nSQL:\n- A language used to interact with database programs\n- Can pull information from different sources in the database\n- Stored across a database\n- Larger datasets\n- Track changes across a team\n- Useful across multiple programs \n\nSome database products have their own variant of SQL, and these different varieties of SQL dialects are what help you communicate with each database product.\n\n- LearnSQL’s blog, [What Is a SQL Dialect, and Which One Should You Learn?](https://learnsql.com/blog/what-sql-dialect-to-learn/)\n- Datacamp’s blog, [SQL Server, PostgreSQL, MySQL... what's the difference? Where do I start?](https://www.datacamp.com/community/blog/sql-differences)\nNote that there is an error in this blog article. The comparison table incorrectly states that SQlite uses subqueries instead of window functions. Refer to the [SQLite Window Functions](https://sqlite.org/windowfunctions.html0) documentation for proper clarification.\n- SQL Tutorial’s tutorial, [What is SQL](https://www.sqltutorial.org/what-is-sql/)\n\n\n## Widely used SQL queries\n\nQueries were run using BigQuery after uploading the file in `data/customer_data.csv` as well as `data/cars.csv` to the sandbox\n\n### Select\n\nSELECT and FROM help specify what data we want to extract from the database and use.\n\n\n\n```{sql}\nSELECT name, city\nFROM `lithe-vault-366813.customer_data.customer_address` \nLIMIT 5\n```\n\n\n\n### Insert data into databases\n\nNotice, with the BigQuery sandbox account, you won't be able to use `INSERT INTO` or `UPDATE`\n\nWe add new data like this:\n\n1. Define into which table we want to add data\n2. Specify which columns we're adding this data to by typing their names in the parentheses\n3. Say what we want to add\n\n\n\n```{sql}\nINSERT INTO `lithe-vault-366813.customer_data.customer_address`\n    (customer_id, adress, city, state, zipcode, country)\nVALUES \n    (2645, '333 SQL Road', 'Jackson', 'MI', 49202, 'US')\n```\n\n\n\nWe change data like this:\n\n1. Define what table we want to update\n2. Let it know what value we're trying to change\n3. Tell SQL where we want to make the change\n\n\n\n```{sql}\nUPDATE `lithe-vault-366813.customer_data.customer_address`\nSET address = '123 New Address'\nWHERE customer_id = 2645\n```\n\n\n\n### Creating a new table\n\nIf we want to create a new table for this database, we can use the `CREATE TABLE IF NOT EXISTS` statement. \n \nKeep in mind, just running a SQL query doesn't actually create a table for the data we extract. It just stores it in our local memory. To save it, we'll need to download it as a spreadsheet or save the result into a new table.\n\nAnother good thing to keep in mind, if you're creating lots of tables within a database, you'll want to use the `DROP TABLE IF EXISTS` statement to clean up after yourself.\n\n\n\n## Cleaning string variables using SQL\n\n### Removing duplicates\n\nEarlier, we covered how to remove duplicates in spreadsheets using the Remove duplicates tool. In SQL, we can do the same thing by including `DISTINCT` in our SELECT statement. \n\n\n\n```{sql}\nSELECT DISTINCT customer_id\nFROM `lithe-vault-366813.customer_data.customer_address` \nLIMIT 20\n```\n\n\n\n\n### LENGTH\n\nIf we already know the length our string variables are supposed to be, we can use LENGTH to double-check that our string variables are consistent. For some databases, this query is written as LEN, but it does the same thing.\n\nTo remind ourselves what our results mean, we can label this column in our results as letters_in_country. \n\n\n\n```{sql}\nSELECT LENGTH(country) AS letters_in_country\nFROM `lithe-vault-366813.customer_data.customer_address` \n```\n\n\n\nIt seems like almost all of them are 2s, which means the country field contains only two letters. But  let's check out if countries are incorrectly listed in our table. \n\n\n\n```{sql}\nSELECT country\nFROM `lithe-vault-366813.customer_data.customer_address` \nWHERE LENGTH(country) > 2\n```\n\n\n\nThe incorrectly listed countries show up as USA instead of US\n\n We still need to fix this problem so we can pull a list of all the customers in the US, including the two that have USA instead of US. The good news is that we can account for this error in our results by using the **substring function** in our SQL query. \n\nWe're going to use the substring function to pull the first two letters of each country so that all of them are consistent and only contain two letters. \n\nTo use the substring function, we first need to tell SQL the column where we found this error, country. Then we specify which letter to start with.Then we specify which letter to start with. We want SQL to pull the first two letters, so we're starting with the first letter, so we type in 1. Then we need to tell SQL how many letters, including this first letter, to pull. Since we want the first two letters, we need SQL to pull two total letters, so we type in 2.\n\n\n\n```{sql}\nSELECT customer_id\nFROM `lithe-vault-366813.customer_data.customer_address` \nWHERE SUBSTR(country, 1, 2) = 'US'\n```\n\n\n\nWhen we run this query, we get a list of all customer IDs of customers whose country is the US, including the customers that had USA instead of US. \n\n\n### TRIM\n\nThis is really useful if you find entries with extra spaces and need to eliminate those extra spaces for consistency.\n\nWe first want SQL to filter for states that have more than two letters:\n\n\n\n```{sql}\nSELECT  state\nFROM `lithe-vault-366813.customer_data.customer_address` \nWHERE LENGTH(state) > 2\n```\n\n\n\nWe have one state that has more than two letters. But hold on, how can this state that seems like it has two letters, O and H for Ohio, have more than two letters? The extra characters must be a space\n\nLets deal with this:\n\n\n\n```{sql}\nSELECT  DISTINCT customer_id\nFROM `lithe-vault-366813.customer_data.customer_address` \nWHERE TRIM(state) = 'OH'\n```\n\n\n\n\n### Find min and max values\n\nIn another dataframe, we inspect car measurements. \nThe length column should contain numeric measurements of the cars. So you will check that the minimum and maximum lengths in the dataset align with the data description, which states that the lengths in this column should range from 141.1 to 208.1. \n\n\n\n```{sql}\nSELECT\n  MIN(length) AS min_length,\n  MAX(length) AS max_length\nFROM `lithe-vault-366813.cars.car_info` \n```\n\n\n\n\n### Missing data\n\nMissing values can create errors or skew your results during analysis. You’re going to want to check your data for null or missing values. These values might appear as a blank cell or the word null in BigQuery. \n\nWe find such instances with:\n\n\n\n```{sql}\nSELECT *\nFROM `lithe-vault-366813.cars.car_info` \nWHERE num_of_doors IS NULL\n```\n\n\n\nThis does not work in the sandbox, but one way to update these values is \n\n\n\n```{sql}\nUPDATE cars.car_info\nSET num_of_doors = \"four\"\nWHERE\n  make = \"dodge\"\n  AND fuel_type = \"gas\"\n  AND body_style = \"sedan\";\n```\n\n\n\n\n### Correct misspellings\n\nImagine some numbers write tow instead of two, we can correct this with:\n\n\n\n```{sql}\nUPDATE cars.car_info\nSET num_of_cylinders = \"two\"\nWHERE num_of_cylinders = \"tow\";\n```\n\n\n\n\n### Check how many rows contain a specific piece of info\n\nWe have measurements of 70, which is too high. Before you delete anything, you should check to see how many rows contain this erroneous value as a precaution so that you don’t end up deleting 50% of your data. If there are too many (for instance, 20% of your rows have the incorrect 70 value), then you would want to check back in with the sales manager to inquire if these should be deleted or if the 70 should be updated to another value. Use the query below to count how many rows you would be deleting:\n\n\n\n```{sql}\nSELECT COUNT(*) AS num_rows_to_delete\nFROM `lithe-vault-366813.cars.car_info` \nWHERE compression_ratio = 70;\n```\n\n\n\n\n### Converting between data types\n\n#### Strings and numbers\n\nCAST can be used to convert anything from one data type to another.\n\nLet's start by trying to the different purchase prices. For this, we loaded the table `data/Furniture-Store-Transaction-Table.csv` into BigQuery\n\n\n\n```{sql}\nSELECT purchase_price  \nFROM `lithe-vault-366813.customer_data.customer_purchase` \nORDER BY purchase_price DESC\n```\n\n\n\nWhen we do this we see there is sth wrong with the order:\n\n1: 89.85  \n2: 799.99  \n3: 58.89  \n\nThe problem is that the database doesn't recognize that these are numbers, so it didn't sort them that way. If we go back to the customer_purchase table and take a look at its schema, we can see what datatype that database thinks purchase underscore price is a string while it is a **float**, i.e. a number that contains a decimal.\n\n**Typecasting** means converting data from one type to another, which is what we'll do with the CAST function.\n\n\n\n```{sql}\nSELECT CAST(purchase_price AS FLOAT64)  \nFROM `lithe-vault-366813.customer_data.customer_purchase` \nORDER BY CAST(purchase_price AS FLOAT64) DESC\n```\n\n\n\n#### Dates\n\nThe furniture store owner has asked us to look at purchases that occurred during their sales promotion period in December. \n\n\n\n```{sql}\nSELECT date, purchase_price \nFROM `lithe-vault-366813.customer_data.customer_purchase` \nWHERE date BETWEEN '2020-12-01' AND '2020-12-31'\n```\n\n\n\nFour purchases occurred in December, but the date field looks odd. That's because the database recognizes this date field as datetime, which consists of the date and time. Our SQL query still works correctly, even if the date field is datetime instead of date. But we can tell SQL to convert the date field into the date data type so we see just the day and not the time. \n\n\n\n```{sql}\nSELECT CAST(date AS date) AS date_only,\n  purchase_price\nFROM `lithe-vault-366813.customer_data.customer_purchase` \nWHERE date BETWEEN '2020-12-01' AND '2020-12-31'\n```\n\n\n\n### Combining strings\n\n**CONCAT** lets you add strings together to create new text strings that can be used as unique keys. \n\nThe owner wants to know if customers prefer certain colors, so the owner can manage store inventory accordingly. The problem is, the product_code is the same, regardless of the product color. We need to find another way to separate products by color.\n\n\n\n```{sql}\nSELECT CONCAT(product_code, product_color) AS new_product_code\nFROM `lithe-vault-366813.customer_data.customer_purchase` \nWHERE product = 'couch'\n```\n\n\n\n\n### Identify non-null values\n\n**COALESCE** can be used to return non-null values in a list. Null values are missing values. If you have a field that's optional in your table, it'll have null in that field for rows that don't have appropriate values to put there. I.e. we have some rows with missing product information.\n\nWe want to use the product_name column to understand what kind of product was sold. We want a list of product names, but if names aren't available, then give us the product code. Here is where we type \"COALESCE.\" then we tell SQL which column to check first, product, and which column to check second if the first column is null, product_code.\n\n\n\n```{sql}\nSELECT DISTINCT COALESCE(product, product_code) AS product_info\nFROM `lithe-vault-366813.customer_data.customer_purchase` \n```\n\n",
    "supporting": [
      "3_sql_and_data_cleaning_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}